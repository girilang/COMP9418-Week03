{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcCBqTqXmXBp"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/UNSW-COMP9418/Week03/blob/main/COMP9418_W03_Bayesian_Networks.ipynb)\n",
        "\n",
        "\n",
        "# Bayesian Networks\n",
        "**COMP9418 W03 Tutorial**\n",
        "\n",
        "- Instructor: Gustavo Batista\n",
        "- School of Computer Science and Engineering, UNSW Sydney\n",
        "- Notebook designed by Gustavo Batista and Jeremy Gillen from a notebook developed by Daniel Mackinlay and Edwin V. Bonilla\n",
        "- Last update 22nd September 2022\n",
        "$$\n",
        "% macros\n",
        "\\newcommand{\\indep}{\\perp \\!\\!\\!\\perp}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjj4J4d8mXBr"
      },
      "source": [
        "In this week's tutorial, we will start exploring representation and inference with Bayesian networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpbYk2rUmXBs"
      },
      "source": [
        "## Technical prerequisites\n",
        "\n",
        "You will need certain packages installed to run this notebook.\n",
        "\n",
        "If you are using Google Colab or ``conda``'s default\n",
        "[full installation](https://conda.io/docs/install/full.html),\n",
        "these requirements should all be satisfied already.\n",
        "\n",
        "If you are using ``virtualenv`` or other native package management,\n",
        "you may need to run this command:\n",
        "\n",
        "```python\n",
        "pip3 install pandas\n",
        "```\n",
        "\n",
        "To render a visualization of some graphical models, you also need to install [Graphviz](http://www.graphviz.org/download). We have already used this library in Tutorial 1, thus, you should have it installed. If you do not have it and use the conda installation, then use the command ```conda install python-graphviz```. \n",
        "\n",
        "You will also need to download the preprocessed `icu_diag.csv` data set (see data file for this tutorial in WebCMS3) and put it in the same folder as this notebook.\n",
        "\n",
        "Once we have done all that, we import some useful modules for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zKWC61cgmXBu"
      },
      "outputs": [],
      "source": [
        "# Necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# combinatorics\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hPCDdghmXBv"
      },
      "source": [
        "Import classes from `DiscreteFactors.py` and `Graph.py` developed in previous tutorials. If you are using Colab, upload the files by clicking the \"files\" \n",
        "![File](https://raw.githubusercontent.com/UNSW-COMP9418/Week03/main/img/file.png) \n",
        "button on the left side of the page, then the \"upload files\" \n",
        "![Upload](https://raw.githubusercontent.com/UNSW-COMP9418/Week03/main/img/upload.png)\n",
        "button. Then select the relevant python files.\n",
        "\n",
        "At this point, you should have your versions of these libraries and we strongly recommend you use them. In the case you want to use our implementation, you can run the next cell to download the files from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iO-RyycpmXBw",
        "outputId": "6b3b62ae-b3de-4ed6-a111-bfd53efe4c3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-26 02:22:20--  https://raw.githubusercontent.com/girilang/COMP9418-Week03/main/DiscreteFactors.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7970 (7.8K) [text/plain]\n",
            "Saving to: ‘DiscreteFactors.py.3’\n",
            "\n",
            "\rDiscreteFactors.py.   0%[                    ]       0  --.-KB/s               \rDiscreteFactors.py. 100%[===================>]   7.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-26 02:22:20 (66.0 MB/s) - ‘DiscreteFactors.py.3’ saved [7970/7970]\n",
            "\n",
            "--2022-09-26 02:22:20--  https://raw.githubusercontent.com/girilang/COMP9418-Week03/main/Graph.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8128 (7.9K) [text/plain]\n",
            "Saving to: ‘Graph.py.1’\n",
            "\n",
            "Graph.py.1          100%[===================>]   7.94K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-26 02:22:20 (68.6 MB/s) - ‘Graph.py.1’ saved [8128/8128]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Only run this cell if you do not want to use your libraries and\n",
        "# prefer to download our implementation from GitHub\n",
        "\n",
        "!wget 'https://raw.githubusercontent.com/girilang/COMP9418-Week03/main/DiscreteFactors.py'\n",
        "!wget 'https://raw.githubusercontent.com/girilang/COMP9418-Week03/main/Graph.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IlXXXMprmXBx"
      },
      "outputs": [],
      "source": [
        "from DiscreteFactors import Factor\n",
        "from Graph import Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbqG12m0mXBx"
      },
      "source": [
        "\n",
        "## `pandas`\n",
        "\n",
        "We will be using an external library for the loading tabular data: `pandas.DataFrame` is somewhat similar to `R`. \n",
        "If you wish to know more about that, [check out the Pandas intro](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html). We will mostly be ignoring this library, except to load data and display it in nice tables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upZU75f8mXBy"
      },
      "source": [
        "\n",
        "\n",
        "# The Data\n",
        "\n",
        "## Loading the data\n",
        "\n",
        "These data correspond to the problem in the theory part of the tutorial for this week, i.e. the Bayesian network for medical diagnosis in an intensive care unit (ICU). The data are in `csv` format.\n",
        "We can load this in several ways in python, but the most convenient for this purpose \n",
        "is to load it as a `DataFrame` in `pandas`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7AZrCfYPmXBy",
        "outputId": "107df264-9838-4450-96a5-051dc34aa960",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-26 02:22:41--  https://raw.githubusercontent.com/UNSW-COMP9418/Week03/main/icu_diag.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18018 (18K) [text/plain]\n",
            "Saving to: ‘icu_diag.csv.1’\n",
            "\n",
            "\ricu_diag.csv.1        0%[                    ]       0  --.-KB/s               \ricu_diag.csv.1      100%[===================>]  17.60K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-09-26 02:22:41 (10.8 MB/s) - ‘icu_diag.csv.1’ saved [18018/18018]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download data\n",
        "!wget 'https://raw.githubusercontent.com/UNSW-COMP9418/Week03/main/icu_diag.csv'\n",
        "\n",
        "data = pd.read_csv(open('icu_diag.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i1i2y07mXBz"
      },
      "source": [
        "The loaded data frame is an attribute-value table. It contais 1000 rows (examples), each one correponding to a patient in the intensive care unit. Each row has nine colums (attributes). Each column correponds to one variable in the Bayesian network. The next figure illustrates the network.\n",
        "\n",
        "![ICU Graph](https://raw.githubusercontent.com/UNSW-COMP9418/Week03/main/img/ICU_graph.png \"Graph exercise\")\n",
        "\n",
        "We can use the command ``data.head()`` to display the first $n$ rows (default = 5) of the data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "0-d84HpemXBz"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-39GbzMmXB0"
      },
      "source": [
        "The values in the cariables are encoded as follows:\n",
        "\n",
        "| Variable  |  Value  |  Coding |\n",
        "| :-------: | :-----: | ------: |\n",
        "| H, L, A   |  False  | 0       |\n",
        "| H, L, A   |  True   | 1       |\n",
        "| V, S, T   |  Low    | 0       |\n",
        "| V, S, T   |  High   | 1       |\n",
        "| C, O, B   |  Low    | 0       |\n",
        "| C, O, B   |  Medium | 1       |\n",
        "| C, O, B   |  High   | 2       |\n",
        "\n",
        "For now, we will keep this encoding as provided in the data file. However, replacing the numerical codes by symbolic labels may improve the results readability. To keep this notebook short, we will leave this extension as an exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV8b1BMPmXB1"
      },
      "source": [
        "# Representing a Bayesian Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6m1r5iVmXB2"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Let's first represent the graph using the Graph object discussed in the Week 1 tutorial. We created a stub for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bsR12UCsmXB2"
      },
      "outputs": [],
      "source": [
        "graph = Graph({\n",
        "    'L': ['S', 'V'],\n",
        "    'H': ['S', 'V'],\n",
        "    'A': ['T'],\n",
        "    'S': ['O'],\n",
        "    'V': ['O', 'C'],\n",
        "    'O': ['B'],\n",
        "    'C': [],\n",
        "    'T': ['B'],\n",
        "    'B': []\n",
        "\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXeB2Ck_mXB4"
      },
      "source": [
        "Let's use GraphViz to display the graph representation, so we can assure we did not forget any edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bRLXTHifmXB4",
        "outputId": "c4a7ce1e-c495-48b5-a5b6-ffb34af9ee7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f3ecd4588d0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"186pt\" height=\"230pt\"\n viewBox=\"0.00 0.00 186.01 230.02\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 226.0186)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-226.0186 182.0124,-226.0186 182.0124,4 -4,4\"/>\n<!-- L -->\n<g id=\"node1\" class=\"node\">\n<title>L</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-204.0186\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-200.3186\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">L</text>\n</g>\n<!-- S -->\n<g id=\"node4\" class=\"node\">\n<title>S</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"89.0062\" cy=\"-142.0124\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"89.0062\" y=\"-138.3124\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">S</text>\n</g>\n<!-- L&#45;&gt;S -->\n<g id=\"edge1\" class=\"edge\">\n<title>L&#45;&gt;S</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M42.01,-189.0086C49.3642,-181.6544 58.3718,-172.6468 66.5264,-164.4922\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.1075,-166.8609 73.7037,-157.3149 64.1577,-161.9111 69.1075,-166.8609\"/>\n</g>\n<!-- V -->\n<g id=\"node5\" class=\"node\">\n<title>V</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-142.0124\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-138.3124\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V</text>\n</g>\n<!-- L&#45;&gt;V -->\n<g id=\"edge2\" class=\"edge\">\n<title>L&#45;&gt;V</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M27,-185.7501C27,-180.9989 27,-175.7647 27,-170.6192\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"30.5001,-170.3646 27,-160.3646 23.5001,-170.3647 30.5001,-170.3646\"/>\n</g>\n<!-- H -->\n<g id=\"node2\" class=\"node\">\n<title>H</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"89.0062\" cy=\"-204.0186\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"89.0062\" y=\"-200.3186\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">H</text>\n</g>\n<!-- H&#45;&gt;S -->\n<g id=\"edge3\" class=\"edge\">\n<title>H&#45;&gt;S</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M89.0062,-185.7501C89.0062,-180.9989 89.0062,-175.7647 89.0062,-170.6192\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"92.5063,-170.3646 89.0062,-160.3646 85.5063,-170.3647 92.5063,-170.3646\"/>\n</g>\n<!-- H&#45;&gt;V -->\n<g id=\"edge4\" class=\"edge\">\n<title>H&#45;&gt;V</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M73.9962,-189.0086C66.642,-181.6544 57.6344,-172.6468 49.4798,-164.4922\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"51.8485,-161.9111 42.3025,-157.3149 46.8987,-166.8609 51.8485,-161.9111\"/>\n</g>\n<!-- A -->\n<g id=\"node3\" class=\"node\">\n<title>A</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"151.0124\" cy=\"-142.0124\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"151.0124\" y=\"-138.3124\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">A</text>\n</g>\n<!-- T -->\n<g id=\"node8\" class=\"node\">\n<title>T</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"151.0124\" cy=\"-80.0062\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"151.0124\" y=\"-76.3062\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">T</text>\n</g>\n<!-- A&#45;&gt;T -->\n<g id=\"edge5\" class=\"edge\">\n<title>A&#45;&gt;T</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M151.0124,-123.7439C151.0124,-118.9927 151.0124,-113.7585 151.0124,-108.613\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"154.5125,-108.3584 151.0124,-98.3584 147.5125,-108.3585 154.5125,-108.3584\"/>\n</g>\n<!-- O -->\n<g id=\"node6\" class=\"node\">\n<title>O</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"89.0062\" cy=\"-80.0062\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"89.0062\" y=\"-76.3062\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">O</text>\n</g>\n<!-- S&#45;&gt;O -->\n<g id=\"edge6\" class=\"edge\">\n<title>S&#45;&gt;O</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M89.0062,-123.7439C89.0062,-118.9927 89.0062,-113.7585 89.0062,-108.613\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"92.5063,-108.3584 89.0062,-98.3584 85.5063,-108.3585 92.5063,-108.3584\"/>\n</g>\n<!-- V&#45;&gt;O -->\n<g id=\"edge7\" class=\"edge\">\n<title>V&#45;&gt;O</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M42.01,-127.0024C49.3642,-119.6482 58.3718,-110.6406 66.5264,-102.486\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.1075,-104.8547 73.7037,-95.3087 64.1577,-99.9049 69.1075,-104.8547\"/>\n</g>\n<!-- C -->\n<g id=\"node7\" class=\"node\">\n<title>C</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-80.0062\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-76.3062\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">C</text>\n</g>\n<!-- V&#45;&gt;C -->\n<g id=\"edge8\" class=\"edge\">\n<title>V&#45;&gt;C</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M27,-123.7439C27,-118.9927 27,-113.7585 27,-108.613\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"30.5001,-108.3584 27,-98.3584 23.5001,-108.3585 30.5001,-108.3584\"/>\n</g>\n<!-- B -->\n<g id=\"node9\" class=\"node\">\n<title>B</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"89.0062\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"89.0062\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B</text>\n</g>\n<!-- O&#45;&gt;B -->\n<g id=\"edge9\" class=\"edge\">\n<title>O&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M89.0062,-61.7377C89.0062,-56.9865 89.0062,-51.7523 89.0062,-46.6068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"92.5063,-46.3522 89.0062,-36.3522 85.5063,-46.3523 92.5063,-46.3522\"/>\n</g>\n<!-- T&#45;&gt;B -->\n<g id=\"edge10\" class=\"edge\">\n<title>T&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M136.0024,-64.9962C128.6482,-57.642 119.6406,-48.6344 111.486,-40.4798\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.8547,-37.8987 104.3087,-33.3025 108.9049,-42.8485 113.8547,-37.8987\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "pos = {\n",
        "    'L': '0,3!',\n",
        "    'H': '1,3!',\n",
        "    'S': '1,2!',\n",
        "    'V': '0,2!',\n",
        "    'A': '2,2!',\n",
        "    'O': '1,1!',\n",
        "    'C': '0,1!',\n",
        "    'T': '2,1!',\n",
        "    'B': '1,0!',\n",
        "}\n",
        "graph.show(positions=pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5xtXaxTmXB6"
      },
      "source": [
        "We will also need to declare a data structure with the possible outcomes for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1Kr4q9IhmXB6"
      },
      "outputs": [],
      "source": [
        "# possible outcomes, by variable\n",
        "outcomeSpace = dict(\n",
        "    H=(0,1),\n",
        "    L=(0,1),\n",
        "    A=(0,1),\n",
        "    V=(0,1),\n",
        "    S=(0,1),\n",
        "    T=(0,1),\n",
        "    C=(0,1,2),\n",
        "    O=(0,1,2),\n",
        "    B=(0,1,2),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIN1tgwzmXB7"
      },
      "source": [
        "Let's combine these two data structures to represent a Bayes net:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6CwmFKZimXB8"
      },
      "outputs": [],
      "source": [
        "class BayesNet():\n",
        "    def __init__(self, graph, outcomeSpace=None, factor_dict=None):\n",
        "        self.graph = graph\n",
        "        self.outcomeSpace = dict()\n",
        "        self.factors = dict()\n",
        "        if outcomeSpace is not None:\n",
        "            self.outcomeSpace = outcomeSpace\n",
        "        if factor_dict is not None:\n",
        "            self.factors = factor_dict\n",
        "        \n",
        "model = BayesNet(graph, outcomeSpace)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bfwg3JimXB8"
      },
      "source": [
        "Note that we have also introduced a variable called `factors`. The purpose of this variable is to hold all the factors associated with the connections in this Bayes Net. We could use a list here, or a set, but since each factor represents the relationship between a child node and its parents, it is convenient to label the factors with the name of the child node. E.g. `self.factors['B']` would contain the probability distribution $P(B|O,T)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWKAHbk5mXB9"
      },
      "source": [
        "# Estimating the probability tables from the data\n",
        "\n",
        "We need to estimate a discrete distribution\n",
        "for each (conditional) probability distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oseKh-a_mXB9"
      },
      "source": [
        "Now we estimate parameters by constructing conditional distributions for each node in our graph.\n",
        "We will take the proportions of empirical counts as estimates of the probabilities of the counted outcomes, i.e.\n",
        "$$\n",
        "\\hat{p}(\\boldsymbol{X_i}=\\boldsymbol{x},\\boldsymbol{Y_i}=\\boldsymbol{y})=\\frac{N_{\\boldsymbol{x}, \\boldsymbol{y}}}{N},\n",
        "$$\n",
        "and\n",
        "$$\n",
        "\\hat{p}(\\boldsymbol{X_i}=\\boldsymbol{x}\\mid\\boldsymbol{Y_i}=\\boldsymbol{y})=\\frac{N_{\\boldsymbol{x}, \\boldsymbol{y}}}{N_\\boldsymbol{y}},\n",
        "$$\n",
        "\n",
        "where $N_{\\boldsymbol{x}, \\boldsymbol{y}}$ is the number of observations of that outcome,\n",
        "$$N_{\\boldsymbol{x}, \\boldsymbol{y}}:=\\sum_i\\boldsymbol{X_i}=\\boldsymbol{x}\\cap\\boldsymbol{Y_i}=\\boldsymbol{y},$$ and $N$ is the total number of observations.\n",
        "\n",
        "Later, we will see this procedure of estimating parameters corresponds to the Maximum Likelihood Estimate (MLE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5Zx9YvimXB-"
      },
      "source": [
        "Below is another helper function. This will calculate joint occurrence probability tables.\n",
        "you invoke it like this\n",
        "```\n",
        "factor = estimateFactor(data, 'V', ['H', 'L'])\n",
        "```\n",
        "to estimate all conditional occurrence probabilities of $V|H,L$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "04b1DP6imXB_",
        "outputId": "cb098e4c-1733-4a88-87ee-44389258957c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒═════╤═════╤═════╤═══════════╕\n",
            "│   H │   L │   V │        Pr │\n",
            "╞═════╪═════╪═════╪═══════════╡\n",
            "│   0 │   0 │   0 │ 0.0447958 │\n",
            "├─────┼─────┼─────┼───────────┤\n",
            "│   0 │   0 │   1 │ 0.955204  │\n",
            "├─────┼─────┼─────┼───────────┤\n",
            "│   0 │   1 │   0 │ 0         │\n",
            "├─────┼─────┼─────┼───────────┤\n",
            "│   0 │   1 │   1 │ 1         │\n",
            "├─────┼─────┼─────┼───────────┤\n",
            "│   1 │   0 │   0 │ 0.994764  │\n",
            "├─────┼─────┼─────┼───────────┤\n",
            "│   1 │   0 │   1 │ 0.0052356 │\n",
            "├─────┼─────┼─────┼───────────┤\n",
            "│   1 │   1 │   0 │ 1         │\n",
            "├─────┼─────┼─────┼───────────┤\n",
            "│   1 │   1 │   1 │ 0         │\n",
            "╘═════╧═════╧═════╧═══════════╛\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
        "    \"\"\"\n",
        "    Helper function to create a boolean index vector into a tabular data structure,\n",
        "    such that we return True only for rows of the table where, e.g.\n",
        "    column_a=fixed_vars['column_a'] and column_b=fixed_vars['column_b'].\n",
        "    \n",
        "    This is a simple task, but it's not *quite* obvious\n",
        "    for various obscure technical reasons.\n",
        "    \n",
        "    It is perhaps best explained by an example.\n",
        "    \n",
        "    >>> all_equal_this_index(\n",
        "    ...    {'X': [1, 1, 0], Y: [1, 0, 1]},\n",
        "    ...    X=1,\n",
        "    ...    Y=1\n",
        "    ... )\n",
        "    [True, False, False]\n",
        "    \"\"\"\n",
        "    # base index is a boolean vector, everywhere true\n",
        "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
        "    index = np.ones_like(first_array, dtype=np.bool_)\n",
        "    for var_name, var_val in fixed_vars.items():\n",
        "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
        "    return index\n",
        "\n",
        "def estimateFactor(data, var_name, parent_names, outcomeSpace):\n",
        "    \"\"\"\n",
        "    Calculate a dictionary probability table by ML given\n",
        "    `data`, a dictionary or dataframe of observations\n",
        "    `var_name`, the column of the data to be used for the conditioned variable and\n",
        "    `parent_names`, a tuple of columns to be used for the parents and\n",
        "    `outcomeSpace`, a dict that maps variable names to a tuple of possible outcomes\n",
        "    Return a dictionary containing an estimated conditional probability table.\n",
        "    \"\"\"    \n",
        "    var_outcomes = outcomeSpace[var_name]\n",
        "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
        "    # cartesian product to generate a table of all possible outcomes\n",
        "    all_parent_combinations = product(*parent_outcomes)\n",
        "\n",
        "    f = Factor(list(parent_names)+[var_name], outcomeSpace)\n",
        "    \n",
        "    for i, parent_combination in enumerate(all_parent_combinations):\n",
        "        parent_vars = dict(zip(parent_names, parent_combination))\n",
        "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
        "        for var_outcome in var_outcomes:\n",
        "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
        "            f[tuple(list(parent_combination)+[var_outcome])] = (var_index & parent_index).sum()/parent_index.sum()\n",
        "            \n",
        "    return f\n",
        "\n",
        "\n",
        "##############################\n",
        "# Test code\n",
        "##############################\n",
        "print(estimateFactor(data, 'V', ['H', 'L'], outcomeSpace))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzafjSw0mXCA"
      },
      "source": [
        "Now, we will use the above function to calculate the probability tables for all 9 variables of the ICU Bayesian Network. \n",
        "\n",
        "However, notice that the `estimateFactor(data, var_name, parent_names, outcomeSpace)` requires the variable name (`var_name`) and the parent names (`parent_names`). We do not have this information readly available. The adjacency list provides the children of each node, not its parents.\n",
        "\n",
        "The question is, how can we invert the graph data structure so that each node will point to its parents? Yes, the answer is the graph transpose operation, implemented in Week 1 tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ehLEvG7dmXCA",
        "outputId": "e6544ba0-5f40-4d1b-9d7a-d675ac52bc27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f3ecd3da690>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"186pt\" height=\"230pt\"\n viewBox=\"0.00 0.00 186.01 230.02\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 226.0186)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-226.0186 182.0124,-226.0186 182.0124,4 -4,4\"/>\n<!-- L -->\n<g id=\"node1\" class=\"node\">\n<title>L</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-204.0186\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-200.3186\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">L</text>\n</g>\n<!-- H -->\n<g id=\"node2\" class=\"node\">\n<title>H</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"89.0062\" cy=\"-204.0186\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"89.0062\" y=\"-200.3186\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">H</text>\n</g>\n<!-- A -->\n<g id=\"node3\" class=\"node\">\n<title>A</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"151.0124\" cy=\"-142.0124\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"151.0124\" y=\"-138.3124\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">A</text>\n</g>\n<!-- S -->\n<g id=\"node4\" class=\"node\">\n<title>S</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"89.0062\" cy=\"-142.0124\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"89.0062\" y=\"-138.3124\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">S</text>\n</g>\n<!-- S&#45;&gt;L -->\n<g id=\"edge1\" class=\"edge\">\n<title>S&#45;&gt;L</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M73.9962,-157.0224C66.642,-164.3766 57.6344,-173.3842 49.4798,-181.5388\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"46.8987,-179.1701 42.3025,-188.7161 51.8485,-184.1199 46.8987,-179.1701\"/>\n</g>\n<!-- S&#45;&gt;H -->\n<g id=\"edge2\" class=\"edge\">\n<title>S&#45;&gt;H</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M89.0062,-160.2809C89.0062,-165.0321 89.0062,-170.2663 89.0062,-175.4118\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"85.5063,-175.6663 89.0062,-185.6664 92.5063,-175.6664 85.5063,-175.6663\"/>\n</g>\n<!-- V -->\n<g id=\"node5\" class=\"node\">\n<title>V</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-142.0124\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-138.3124\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">V</text>\n</g>\n<!-- V&#45;&gt;L -->\n<g id=\"edge3\" class=\"edge\">\n<title>V&#45;&gt;L</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M27,-160.2809C27,-165.0321 27,-170.2663 27,-175.4118\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"23.5001,-175.6663 27,-185.6664 30.5001,-175.6664 23.5001,-175.6663\"/>\n</g>\n<!-- V&#45;&gt;H -->\n<g id=\"edge4\" class=\"edge\">\n<title>V&#45;&gt;H</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M42.01,-157.0224C49.3642,-164.3766 58.3718,-173.3842 66.5264,-181.5388\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"64.1577,-184.1199 73.7037,-188.7161 69.1075,-179.1701 64.1577,-184.1199\"/>\n</g>\n<!-- O -->\n<g id=\"node6\" class=\"node\">\n<title>O</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"89.0062\" cy=\"-80.0062\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"89.0062\" y=\"-76.3062\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">O</text>\n</g>\n<!-- O&#45;&gt;S -->\n<g id=\"edge5\" class=\"edge\">\n<title>O&#45;&gt;S</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M89.0062,-98.2747C89.0062,-103.0259 89.0062,-108.2601 89.0062,-113.4056\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"85.5063,-113.6601 89.0062,-123.6602 92.5063,-113.6602 85.5063,-113.6601\"/>\n</g>\n<!-- O&#45;&gt;V -->\n<g id=\"edge6\" class=\"edge\">\n<title>O&#45;&gt;V</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M73.9962,-95.0162C66.642,-102.3704 57.6344,-111.378 49.4798,-119.5326\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"46.8987,-117.1639 42.3025,-126.7099 51.8485,-122.1137 46.8987,-117.1639\"/>\n</g>\n<!-- C -->\n<g id=\"node7\" class=\"node\">\n<title>C</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-80.0062\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-76.3062\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">C</text>\n</g>\n<!-- C&#45;&gt;V -->\n<g id=\"edge7\" class=\"edge\">\n<title>C&#45;&gt;V</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M27,-98.2747C27,-103.0259 27,-108.2601 27,-113.4056\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"23.5001,-113.6601 27,-123.6602 30.5001,-113.6602 23.5001,-113.6601\"/>\n</g>\n<!-- T -->\n<g id=\"node8\" class=\"node\">\n<title>T</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"151.0124\" cy=\"-80.0062\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"151.0124\" y=\"-76.3062\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">T</text>\n</g>\n<!-- T&#45;&gt;A -->\n<g id=\"edge8\" class=\"edge\">\n<title>T&#45;&gt;A</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M151.0124,-98.2747C151.0124,-103.0259 151.0124,-108.2601 151.0124,-113.4056\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"147.5125,-113.6601 151.0124,-123.6602 154.5125,-113.6602 147.5125,-113.6601\"/>\n</g>\n<!-- B -->\n<g id=\"node9\" class=\"node\">\n<title>B</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"89.0062\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"89.0062\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B</text>\n</g>\n<!-- B&#45;&gt;O -->\n<g id=\"edge9\" class=\"edge\">\n<title>B&#45;&gt;O</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M89.0062,-36.2685C89.0062,-41.0197 89.0062,-46.2539 89.0062,-51.3994\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"85.5063,-51.6539 89.0062,-61.654 92.5063,-51.654 85.5063,-51.6539\"/>\n</g>\n<!-- B&#45;&gt;T -->\n<g id=\"edge10\" class=\"edge\">\n<title>B&#45;&gt;T</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M104.0162,-33.01C111.3704,-40.3642 120.378,-49.3718 128.5326,-57.5264\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"126.1639,-60.1075 135.7099,-64.7037 131.1137,-55.1577 126.1639,-60.1075\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "graphT = graph.transpose()\n",
        "graphT.show(positions=pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54q46HvDmXCB"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njOot8ORmXCB"
      },
      "source": [
        "Implement a method on the class BayesNet to learn each conditional factor. Since a Bayesian network contains factors over each variable, conditional on its parents, it's convienient to store each factor in a dictionary. The dictionary will associate each child variable name with a conditional factor: $\\phi(child | parents)$.\n",
        "\n",
        "Use the `estimateFactor(data, var_name, parent_names, outcomeSpace)` function to calculate probability tables for all 9 variables in our DAG (Bayesian network structure in the theory part of the tutorial)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBwNcnFvmXCB"
      },
      "outputs": [],
      "source": [
        "class BayesNet(BayesNet):\n",
        "    def learnParameters(self, data):\n",
        "        '''\n",
        "        Iterate over each node in the graph, and use the given data\n",
        "        to estimate the factor P(node|parents), then add the new factor \n",
        "        to the `self.factors` dictionary.\n",
        "        '''\n",
        "        graphT = self.graph.transpose()\n",
        "        for node, parents in graphT.adj_list.items():\n",
        "            # TODO estimate each factor and add it to the `self.factors` dictionary\n",
        "            ...\n",
        "            \n",
        "##############################\n",
        "# Test code\n",
        "##############################            \n",
        "model = BayesNet(graph, outcomeSpace)\n",
        "model.learnParameters(data)\n",
        "print('estimated P(H)=')\n",
        "print(model.factors['H'])\n",
        "print('estimated P(V|H,L)=')\n",
        "print(model.factors['V'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i-fY8QmmXCC"
      },
      "source": [
        "If you implemented this code correctly, you should see an output like this:\n",
        "    \n",
        "```\n",
        "estimated P(H)=\n",
        "╒═════╤═══════╕\n",
        "│   H │    Pr │\n",
        "╞═════╪═══════╡\n",
        "│   0 │ 0.801 │\n",
        "├─────┼───────┤\n",
        "│   1 │ 0.199 │\n",
        "╘═════╧═══════╛\n",
        "\n",
        "estimated P(V|H,L)=\n",
        "╒═════╤═════╤═════╤═══════════╕\n",
        "│   L │   H │   V │        Pr │\n",
        "╞═════╪═════╪═════╪═══════════╡\n",
        "│   0 │   0 │   0 │ 0.0447958 │\n",
        "├─────┼─────┼─────┼───────────┤\n",
        "│   0 │   0 │   1 │ 0.955204  │\n",
        "├─────┼─────┼─────┼───────────┤\n",
        "│   0 │   1 │   0 │ 0.994764  │\n",
        "├─────┼─────┼─────┼───────────┤\n",
        "│   0 │   1 │   1 │ 0.0052356 │\n",
        "├─────┼─────┼─────┼───────────┤\n",
        "│   1 │   0 │   0 │ 0         │\n",
        "├─────┼─────┼─────┼───────────┤\n",
        "│   1 │   0 │   1 │ 1         │\n",
        "├─────┼─────┼─────┼───────────┤\n",
        "│   1 │   1 │   0 │ 1         │\n",
        "├─────┼─────┼─────┼───────────┤\n",
        "│   1 │   1 │   1 │ 0         │\n",
        "╘═════╧═════╧═════╧═══════════╛\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLjwkJwpmXCD"
      },
      "source": [
        "# Conditional probabilities by naïve summation\n",
        "\n",
        "We are interested in calculating the conditional distributions.\n",
        "For the moment we will attempt to find the conditional distribution\n",
        "$p(L\\mid C=\\text{high})$.\n",
        "\n",
        "We will compute $p(L\\mid C=\\text{high})$ by naïve summation.\n",
        "\n",
        "To do this, we will need to reconstruct each of the joint probabilities from our graph.\n",
        "Remember that we know that we know a factorization for the joint probabilities,\n",
        "specifically,\n",
        "\n",
        "$$p(B,T,O,C,V,S,H,L,A)=p(B\\mid O,T)p(T\\mid A)p(O\\mid V,S)p(C\\mid V)p(V\\mid H,L)p(S\\mid H,L)p(H)p(L)p(A)$$\n",
        "\n",
        "To calculate this, we will need the factor multiplication operation we implemented in the previous tutorial (Week 2). We called this operation a `factor join`. Recall how we use this method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGxVuZDlmXCE"
      },
      "outputs": [],
      "source": [
        "factor1 = model.factors['H']\n",
        "factor2 = model.factors['V']\n",
        "print(\"join p(V|H,L) and p(H):\")\n",
        "print(factor1.join(factor2))\n",
        "\n",
        "# Equivalently, we can do:\n",
        "# print(factor1*factor2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysA9JY7umXCE"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Now, implement a function that calculates the full joint probability of the Bayesian network model by multiplying all conditional distributions estimated from data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BzoDTVqmXCE"
      },
      "outputs": [],
      "source": [
        "class BayesNet(BayesNet):\n",
        "    def joint(self):\n",
        "        '''\n",
        "        Join every factor in the network, and return the resulting factor.\n",
        "        '''\n",
        "        factor_list = list(self.factors.values())\n",
        "        \n",
        "        accumulator = factor_list[0]\n",
        "        ... # TODO join every factor in the list (requires loop)\n",
        "        \n",
        "        return accumulator\n",
        "    \n",
        "#########################\n",
        "# Test code\n",
        "#########################\n",
        "model = BayesNet(graph, outcomeSpace)\n",
        "model.learnParameters(data)\n",
        "p = model.joint()\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMUf8xhvmXCF"
      },
      "source": [
        "The correct implementation should provide the following output. The columns may be in a different order, depending on the order that the factors were joined. At least you can compare the first row.\n",
        "\n",
        "Notice the size of this table as well as some very small probability values. We can realize how difficult it is to elicit such a probability table from a domain expert. It is much easier to work with smaller conditional tables.\n",
        "\n",
        "```\n",
        "╒═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════╤═════════════╕\n",
        "│   L │   H │   S │   V │   O │   A │   T │   C │   B │          Pr │\n",
        "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════════════╡\n",
        "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │ 0.000363366 │\n",
        "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
        "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │   1 │ 0           │\n",
        "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
        "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   0 │   2 │ 0           │\n",
        "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
        "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   1 │   0 │ 1.66682e-05 │\n",
        "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
        "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   1 │   1 │ 0           │\n",
        "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
        "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   1 │   2 │ 0           │\n",
        "├─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────┼─────────────┤\n",
        "│   0 │   0 │   0 │   0 │   0 │   0 │   0 │   2 │   0 │ 6.66726e-06 │\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1ylW5DKmXCG"
      },
      "source": [
        "# Answering Probabilistic Queries\n",
        "\n",
        "Given the joint distribution, we can answer any probabilistic queries we like. For instance, the query we posed before, $p(L\\mid C=\\text{high})$.\n",
        "\n",
        "We will need to eliminate variables through marginalization as well as observing evidence and renormalizing. We have implemented three functions to perform these tasks in Week 2 tutorial.\n",
        "\n",
        "See [this](https://stackoverflow.com/a/36908) stackoverflow answer for the various uses of ** and * for packing and unpacking arguments, as used below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVxNJTKkmXCG"
      },
      "outputs": [],
      "source": [
        "# Reminder of how to use evidence, marginalize, normalize\n",
        "\n",
        "# Create an empty factor ()\n",
        "f = Factor(['A','B','C'], {'A':[0,1], 'B':[0,1,2], 'C':[0,1]})\n",
        "\n",
        "# How to set evidence\n",
        "evidence_dict = {'A':1, 'B':2}\n",
        "f_with_evidence = f.evidence(**evidence_dict) \n",
        "\n",
        "# How to marginalize\n",
        "f_without_c = f.marginalize('C')\n",
        "\n",
        "# How to join 'f' and 'f_without_c'\n",
        "f_joined = f.join(f_without_c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6LxlSKxmXCH"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Implement a method `query` that receives as arguments a list of variables and a list of evidence and returns $P(variables|evidence)$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-obLX4jmXCH"
      },
      "outputs": [],
      "source": [
        "class BayesNet(BayesNet):\n",
        "    def query(self, q_vars, **q_evi):\n",
        "        \"\"\"\n",
        "        arguments \n",
        "        `q_vars`, list of variables in query head\n",
        "        `q_evi`, dictionary of evidence in the form of variables names and values\n",
        "\n",
        "        Returns a new NORMALIZED factor will all hidden variables eliminated as evidence set as in q_evi\n",
        "        \"\"\"     \n",
        "\n",
        "        # first we calculate the joint distribution\n",
        "        f = self.joint()\n",
        "        \n",
        "        # Next, we set the evidence \n",
        "        f = ... # TODO\n",
        "\n",
        "        # Second, we eliminate hidden variables NOT in the query\n",
        "        ... # TODO\n",
        "        \n",
        "        # Finally, we normalize, then return the factor\n",
        "        return ... # TODO\n",
        "\n",
        "#########################\n",
        "# Test code\n",
        "#########################\n",
        "model = BayesNet(graph, outcomeSpace)\n",
        "model.learnParameters(data)\n",
        "         \n",
        "print(model.query('L', C=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1cumI_wmXCH"
      },
      "source": [
        "If your implementation is correct then you should see the following output:\n",
        "\n",
        "```\n",
        "╒═════╤═══════════╕\n",
        "│   L │        Pr │\n",
        "╞═════╪═══════════╡\n",
        "│   0 │ 0.947912  │\n",
        "├─────┼───────────┤\n",
        "│   1 │ 0.0520882 │\n",
        "╘═════╧═══════════╛\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwRoDFUYmXCI"
      },
      "source": [
        "# Conditional independence\n",
        "\n",
        "In this part, we will numerically estimate conditional independences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sozYpOasmXCI"
      },
      "source": [
        "## Exercise\n",
        "Show or refute  the conditional independences in the theory tutorial numerically. i.e. \n",
        "determine whether\n",
        "\n",
        "1. $H \\indep L$\n",
        "2. $H \\indep A$\n",
        "3. $C \\indep L$\n",
        "\n",
        "We can do this by examining the conditional versus marginal probabilities, e.g. \n",
        "\n",
        "$$H \\indep L\\Rightarrow p(H,L)=p(H)p(L)$$\n",
        "\n",
        "Or,\n",
        "\n",
        "$$H \\indep L \\Rightarrow p(H|L)=p(H).$$\n",
        "\n",
        "It is your turn, we will leave three blank cells for you to develop your code. Use the functions we have implemented in the tutorials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxjz7n61mXCI"
      },
      "outputs": [],
      "source": [
        "model = BayesNet(graph, outcomeSpace)\n",
        "model.learnParameters(data)\n",
        "\n",
        "... # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zg83qEVvmXCJ"
      },
      "outputs": [],
      "source": [
        "... # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7oWorSWmXCJ"
      },
      "outputs": [],
      "source": [
        "... # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBgDObmRmXCJ"
      },
      "source": [
        "## Final Task\n",
        "Create a python file called `BayesNet.py`, and copy the BayesNet class into this file (and the helper functions, and import statements). You will need this file for future tutorials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M5w8j-OmXCJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "navigate_num": "#000000",
        "navigate_text": "#333333",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700",
        "sidebar_border": "#EEEEEE",
        "wrapper_background": "#FFFFFF"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "198px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_position": {
        "height": "783px",
        "left": "0px",
        "right": "1346.87px",
        "top": "108px",
        "width": "212px"
      },
      "toc_section_display": "block",
      "toc_window_display": true,
      "widenNotebook": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}